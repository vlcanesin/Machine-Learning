{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ab4e5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "keras = tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ccdba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_ftrain, y_ftrain), (X_test, y_test)  = keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train, X_val = X_ftrain[:50000], X_ftrain[50000:]\n",
    "y_train, y_val = y_ftrain[:50000], y_ftrain[50000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c4503399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28) (50000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4159dbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_trains = scaler.fit_transform(X_train.reshape(-1, 28*28)).reshape(-1, 28, 28)\n",
    "X_vals = scaler.transform(X_val.reshape(-1, 28*28)).reshape(-1, 28, 28)\n",
    "X_tests = scaler.transform(X_test.reshape(-1, 28*28)).reshape(-1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15a160ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Standardization(keras.layers.Layer): \n",
    "    def adapt(self, data_sample): \n",
    "        self.means_ = np.mean(data_sample, axis = 0, keepdims = True) \n",
    "        self.stds_ = np.std(data_sample, axis = 0, keepdims = True) \n",
    "    def call(self, inputs): \n",
    "        return (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a01d84ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#std_layer = Standardization()\n",
    "#std_layer.adapt(X_train)\n",
    "\n",
    "cnn = keras.models.Sequential([\n",
    "    #std_layer,\n",
    "    keras.layers.Conv2D(\n",
    "        10, 7,   # Big kernel preseves spatial information,\n",
    "        padding = 'valid',  # reduces dimensionality\n",
    "        input_shape = (28, 28, 1),\n",
    "        activation = 'relu'\n",
    "    ),\n",
    "    keras.layers.Conv2D(\n",
    "        18, 5,    # Smaller kernel (but more layers)\n",
    "        padding = 'same',  # preserves dimensionality\n",
    "        strides = (1, 1),\n",
    "        activation = 'relu'\n",
    "    ),\n",
    "    keras.layers.MaxPooling2D(\n",
    "        pool_size = (2, 2),\n",
    "        padding = 'same',   # ensuring the kernel will be inside the img\n",
    "        strides = (2, 2),  # reduces dimensionality\n",
    "    ),\n",
    "    keras.layers.Conv2D(\n",
    "        25, 3,    # Smaller kernel (but more layers)\n",
    "        padding = 'same',  # preserves dimensionality\n",
    "        strides = (1, 1),\n",
    "        activation = 'relu'\n",
    "    ),\n",
    "    keras.layers.MaxPooling2D(\n",
    "        pool_size = (3, 3),\n",
    "        padding = 'same',   # ensuring the kernel will be inside the img\n",
    "        strides = (3, 3),  # reduces dimensionality \n",
    "    ),\n",
    "    keras.layers.Flatten(),  # 2D feature maps into neurons\n",
    "    keras.layers.Dropout(rate = 0.2),  # regularization\n",
    "    keras.layers.Dense(150, activation = 'relu'),\n",
    "    keras.layers.Dropout(rate = 0.3),  # regularization\n",
    "    keras.layers.Dense(10, activation = 'softmax')  # finally, the output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e29c795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    optimizer = 'nadam',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c181b53c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_111 (Conv2D)          (None, 22, 22, 10)        500       \n",
      "_________________________________________________________________\n",
      "conv2d_112 (Conv2D)          (None, 22, 22, 18)        4518      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_74 (MaxPoolin  (None, 11, 11, 18)        0         \n",
      "g2D)                                                             \n",
      "_________________________________________________________________\n",
      "conv2d_113 (Conv2D)          (None, 11, 11, 25)        4075      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_75 (MaxPoolin  (None, 4, 4, 25)          0         \n",
      "g2D)                                                             \n",
      "_________________________________________________________________\n",
      "flatten_37 (Flatten)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 150)               60150     \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 10)                1510      \n",
      "_________________________________________________________________\n",
      "=================================================================\n",
      "Total params: 70,753\n",
      "Trainable params: 70,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ba429b69",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 0.2170 - accuracy: 0.9312 - val_loss: 0.0525 - val_accuracy: 0.9854\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 0.0826 - accuracy: 0.9745 - val_loss: 0.0479 - val_accuracy: 0.9856\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 0.0665 - accuracy: 0.9792 - val_loss: 0.0490 - val_accuracy: 0.9860\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 0.0545 - accuracy: 0.9827 - val_loss: 0.0409 - val_accuracy: 0.9891\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 0.0502 - accuracy: 0.9839 - val_loss: 0.0421 - val_accuracy: 0.9890\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 41s 27ms/step - loss: 0.0430 - accuracy: 0.9856 - val_loss: 0.0464 - val_accuracy: 0.9889\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 0.0422 - accuracy: 0.9868 - val_loss: 0.0462 - val_accuracy: 0.9897\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 38s 24ms/step - loss: 0.0384 - accuracy: 0.9879 - val_loss: 0.0422 - val_accuracy: 0.9887\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 38s 24ms/step - loss: 0.0361 - accuracy: 0.9892 - val_loss: 0.0431 - val_accuracy: 0.9895\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 38s 25ms/step - loss: 0.0356 - accuracy: 0.9886 - val_loss: 0.0441 - val_accuracy: 0.9905\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 38s 25ms/step - loss: 0.0314 - accuracy: 0.9901 - val_loss: 0.0440 - val_accuracy: 0.9895\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 38s 24ms/step - loss: 0.0340 - accuracy: 0.9894 - val_loss: 0.0491 - val_accuracy: 0.9904\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 0.0336 - accuracy: 0.9894 - val_loss: 0.0393 - val_accuracy: 0.9919\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 38s 25ms/step - loss: 0.0304 - accuracy: 0.9908 - val_loss: 0.0419 - val_accuracy: 0.9912\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 38s 24ms/step - loss: 0.0281 - accuracy: 0.9909 - val_loss: 0.0503 - val_accuracy: 0.9900\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 38s 24ms/step - loss: 0.0278 - accuracy: 0.9910 - val_loss: 0.0536 - val_accuracy: 0.9914\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 38s 25ms/step - loss: 0.0285 - accuracy: 0.9913 - val_loss: 0.0553 - val_accuracy: 0.9894\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 0.0277 - accuracy: 0.9913 - val_loss: 0.0500 - val_accuracy: 0.9914\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 38s 24ms/step - loss: 0.0264 - accuracy: 0.9920 - val_loss: 0.0542 - val_accuracy: 0.9900\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 38s 24ms/step - loss: 0.0276 - accuracy: 0.9917 - val_loss: 0.0543 - val_accuracy: 0.9904\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 38s 24ms/step - loss: 0.0277 - accuracy: 0.9920 - val_loss: 0.0570 - val_accuracy: 0.9913\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 0.0259 - accuracy: 0.9919 - val_loss: 0.0554 - val_accuracy: 0.9905\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 40s 25ms/step - loss: 0.0261 - accuracy: 0.9916 - val_loss: 0.0542 - val_accuracy: 0.9895\n"
     ]
    }
   ],
   "source": [
    "early_cb = keras.callbacks.EarlyStopping(patience = 10)\n",
    "\n",
    "history = cnn.fit(X_trains, y_train, epochs=50, validation_data = (X_vals, y_val), callbacks = [early_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ea24b015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0432 - accuracy: 0.9906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04315502569079399, 0.9905999898910522]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(X_tests, y_test)  # yessss!! More than 99% accurate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "106ace60",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_108 (Conv2D)          (None, 28, 28, 10)        500       \n",
      "_________________________________________________________________\n",
      "conv2d_109 (Conv2D)          (None, 28, 28, 18)        4518      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_72 (MaxPoolin  (None, 14, 14, 18)        0         \n",
      "g2D)                                                             \n",
      "_________________________________________________________________\n",
      "conv2d_110 (Conv2D)          (None, 14, 14, 25)        4075      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_73 (MaxPoolin  (None, 5, 5, 25)          0         \n",
      "g2D)                                                             \n",
      "_________________________________________________________________\n",
      "flatten_36 (Flatten)         (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 150)               93900     \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 10)                1510      \n",
      "_________________________________________________________________\n",
      "=================================================================\n",
      "Total params: 104,503\n",
      "Trainable params: 104,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "super_cnn = keras.models.Sequential([\n",
    "    #std_layer,\n",
    "    keras.layers.Conv2D(\n",
    "        10, 7,   # Big kernel preseves spatial information,\n",
    "        padding = 'same',  # PRESERVES dimensionality\n",
    "        input_shape = (28, 28, 1),\n",
    "        activation = 'relu'\n",
    "    ),\n",
    "    keras.layers.Conv2D(\n",
    "        18, 5,    # Smaller kernel (but more layers)\n",
    "        padding = 'same',  # preserves dimensionality\n",
    "        strides = (1, 1),\n",
    "        activation = 'relu'\n",
    "    ),\n",
    "    keras.layers.MaxPooling2D(\n",
    "        pool_size = (2, 2),\n",
    "        padding = 'same',   # ensuring the kernel will be inside the img\n",
    "        strides = (2, 2),  # reduces dimensionality\n",
    "    ),\n",
    "    keras.layers.Conv2D(\n",
    "        25, 3,    # Smaller kernel (but more layers)\n",
    "        padding = 'same',  # preserves dimensionality\n",
    "        strides = (1, 1),\n",
    "        activation = 'relu'\n",
    "    ),\n",
    "    keras.layers.MaxPooling2D(\n",
    "        pool_size = (3, 3),\n",
    "        padding = 'same',   # ensuring the kernel will be inside the img\n",
    "        strides = (3, 3),  # reduces dimensionality \n",
    "    ),\n",
    "    keras.layers.Flatten(),  # 2D feature maps into neurons\n",
    "    keras.layers.Dropout(rate = 0.2),  # regularization\n",
    "    keras.layers.Dense(150, activation = 'relu'),\n",
    "    keras.layers.Dropout(rate = 0.3),  # regularization\n",
    "    keras.layers.Dense(10, activation = 'softmax')  # finally, the output layer\n",
    "])\n",
    "\n",
    "super_cnn.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    optimizer = 'nadam',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "super_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b231c03e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 62s 39ms/step - loss: 0.2282 - accuracy: 0.9297 - val_loss: 0.0756 - val_accuracy: 0.9766\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 60s 39ms/step - loss: 0.0915 - accuracy: 0.9710 - val_loss: 0.0514 - val_accuracy: 0.9857\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.0726 - accuracy: 0.9783 - val_loss: 0.0442 - val_accuracy: 0.9862\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 0.0612 - accuracy: 0.9803 - val_loss: 0.0478 - val_accuracy: 0.9877\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 62s 39ms/step - loss: 0.0553 - accuracy: 0.9832 - val_loss: 0.0440 - val_accuracy: 0.9885\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 60s 39ms/step - loss: 0.0492 - accuracy: 0.9843 - val_loss: 0.0457 - val_accuracy: 0.9884\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 61s 39ms/step - loss: 0.0467 - accuracy: 0.9854 - val_loss: 0.0468 - val_accuracy: 0.9890\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 61s 39ms/step - loss: 0.0427 - accuracy: 0.9869 - val_loss: 0.0501 - val_accuracy: 0.9870\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 62s 39ms/step - loss: 0.0398 - accuracy: 0.9875 - val_loss: 0.0641 - val_accuracy: 0.9884\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 0.0412 - accuracy: 0.9867 - val_loss: 0.0503 - val_accuracy: 0.9897\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 60s 39ms/step - loss: 0.0358 - accuracy: 0.9888 - val_loss: 0.0602 - val_accuracy: 0.9900\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0389 - accuracy: 0.9878 - val_loss: 0.0547 - val_accuracy: 0.9907\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 63s 40ms/step - loss: 0.0332 - accuracy: 0.9897 - val_loss: 0.0652 - val_accuracy: 0.9888\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 63s 40ms/step - loss: 0.0340 - accuracy: 0.9894 - val_loss: 0.0720 - val_accuracy: 0.9896\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 0.0328 - accuracy: 0.9899 - val_loss: 0.0821 - val_accuracy: 0.9909\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0525 - accuracy: 0.9894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.052479736506938934, 0.9894000291824341]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_early_cb = keras.callbacks.EarlyStopping(patience = 10)\n",
    "\n",
    "history = super_cnn.fit(X_trains, y_train, epochs=50, validation_data = (X_vals, y_val), callbacks = [super_early_cb])\n",
    "super_cnn.evaluate(X_tests, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970c0277",
   "metadata": {},
   "source": [
    "# Testing on a new dataset with transfer learning\n",
    "### (The dataset in the 'actual_files' folder was created through automating a google search for images of certain landscapes, augmenting the dataset so that every class has the same amount of images and resizing every image to a 183x183 shape)\n",
    "### (Also, I'm using a pretrained model to speed up the process and make the model more accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6088422e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1440 files belonging to 6 classes.\n",
      "Found 180 files belonging to 6 classes.\n",
      "Found 180 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "#LOADING THE DATA\n",
    "\n",
    "img_height = img_width = 224  # ResNet uses 224x224 imgs\n",
    "batch_size = 12  # small batch size since the images are so big\n",
    "\n",
    "train_set = keras.preprocessing.image_dataset_from_directory(\n",
    "  'actual_train_files',\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_set = keras.preprocessing.image_dataset_from_directory(\n",
    "  'actual_val_files',\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_set = keras.preprocessing.image_dataset_from_directory(\n",
    "  'actual_test_files',\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "616e288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    return x/255, y  # set has images (x) and labels (y)\n",
    "\n",
    "train_set.map(preprocess)\n",
    "val_set.map(preprocess)\n",
    "test_set.map(preprocess)\n",
    "\n",
    "#AUTOTUNE = tf.data.AUTOTUNE  # lets the parameter be optimized by tensorflow\n",
    "\n",
    "train_set = train_set.shuffle(500).cache().prefetch(1)\n",
    "val_set = val_set.cache().prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1f44460a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, None, None,  0           []                               \n",
      "                                 3)]                                                              \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None,   0           ['input_5[0][0]']                \n",
      "                                3)                                                                \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, None, None,   9472        ['conv1_pad[0][0]']              \n",
      "                                64)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, None, None,   256         ['conv1_conv[0][0]']             \n",
      "                                64)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, None, None,   0           ['conv1_bn[0][0]']               \n",
      "                                64)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, None, None,   0           ['conv1_relu[0][0]']             \n",
      "                                64)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, None, None,   0           ['pool1_pad[0][0]']              \n",
      "                                64)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, None, None,   4160        ['pool1_pool[0][0]']             \n",
      "                                64)                                                               \n",
      "__________________________________________________________________________________________________\n",
  
      "            ...                            ...                            ...                       "
      
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "res_net_model = keras.applications.resnet50.ResNet50(weights=\"imagenet\", include_top = False)\n",
    "\n",
    "res_net_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d550f8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = res_net_model \n",
    "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)  # makes the final layer shorter and accessible to a dense layer\n",
    "output = keras.layers.Dense(6, activation = \"softmax\")(avg) \n",
    "\n",
    "model = keras.Model(inputs = base_model.input, outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7e2d8980",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, None, None,  0           []                               \n",
      "                                 3)]                                                              \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None,   0           ['input_5[0][0]']                \n",
      "                                3)                                                                \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, None, None,   9472        ['conv1_pad[0][0]']              \n",
      "                                64)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, None, None,   256         ['conv1_conv[0][0]']             \n",
      "                                64)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, None, None,   0           ['conv1_bn[0][0]']               \n",
      "                                64)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, None, None,   0           ['conv1_relu[0][0]']             \n",
      "                                64)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, None, None,   0           ['pool1_pad[0][0]']              \n",
      "                                64)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, None, None,   4160        ['pool1_pool[0][0]']             \n",
      "                                64)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormal  (None, None, None,   256         ['conv2_block1_1_conv[0][0]']    \n",
      "ization)                        64)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activatio  (None, None, None,   0           ['conv2_block1_1_bn[0][0]']      \n",
      "n)                              64)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, None, None,   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                64)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormal  (None, None, None,   256         ['conv2_block1_2_conv[0][0]']    \n",
      "ization)                        64)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activatio  (None, None, None,   0           ['conv2_block1_2_bn[0][0]']      \n",
      "n)                              64)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, None, None,   16640       ['pool1_pool[0][0]']             \n",
      "                                256)                                                              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, None, None,   16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                256)                                                              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormal  (None, None, None,   1024        ['conv2_block1_0_conv[0][0]']    \n",
      "ization)                        256)                                                              \n",
      "__________________________________________________________________________________________________\n",

      "            ...                            ...                            ...                       "
      
      "Total params: 23,600,006\n",
      "Trainable params: 12,294\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False  # freezing the pretrained model for now\n",
    "    \n",
    "model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    optimizer = keras.optimizers.Nadam(learning_rate = 0.001), \n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "532bb166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "120/120 [==============================] - 106s 857ms/step - loss: 0.7397 - accuracy: 0.7437 - val_loss: 0.6042 - val_accuracy: 0.8222\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 104s 864ms/step - loss: 0.3004 - accuracy: 0.9097 - val_loss: 0.5386 - val_accuracy: 0.8278\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 104s 866ms/step - loss: 0.1955 - accuracy: 0.9500 - val_loss: 0.5097 - val_accuracy: 0.8389\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 103s 862ms/step - loss: 0.1394 - accuracy: 0.9701 - val_loss: 0.4929 - val_accuracy: 0.8500\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 102s 852ms/step - loss: 0.1046 - accuracy: 0.9847 - val_loss: 0.4831 - val_accuracy: 0.8611\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 100s 832ms/step - loss: 0.0812 - accuracy: 0.9903 - val_loss: 0.4769 - val_accuracy: 0.8611\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 100s 835ms/step - loss: 0.0648 - accuracy: 0.9937 - val_loss: 0.4732 - val_accuracy: 0.8611\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 100s 832ms/step - loss: 0.0526 - accuracy: 0.9965 - val_loss: 0.4710 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16640c73070>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_cb = keras.callbacks.EarlyStopping(patience = 3)\n",
    "\n",
    "model.fit(train_set, epochs=8, validation_data = val_set, callbacks = [early_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e8f6f9d6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, None, None,  0           []                               \n",
      "                                 3)]                                                              \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None,   0           ['input_5[0][0]']                \n",
      "                                3)                                                                \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, None, None,   9472        ['conv1_pad[0][0]']              \n",
      "                                64)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, None, None,   256         ['conv1_conv[0][0]']             \n",
      "                                64)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, None, None,   0           ['conv1_bn[0][0]']               \n",
      "                                64)                                                               \n",
      "__________________________________________________________________________________________________\n",

      "            ...                            ...                            ...                       "
      
      "Total params: 23,600,006\n",
      "Trainable params: 23,546,886\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = True  # UNfreezing the pretrained model to achieve better performance\n",
    "    \n",
    "model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    optimizer = keras.optimizers.Nadam(learning_rate = 0.0001),  \n",
    "    # a very low lr for Nadam so that the pretrained model doesn't get too disturbed\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c46e87dc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "120/120 [==============================] - 512s 4s/step - loss: 0.4469 - accuracy: 0.8562 - val_loss: 0.9488 - val_accuracy: 0.7778\n",
      "Epoch 2/20\n",
      "120/120 [==============================] - 505s 4s/step - loss: 0.0529 - accuracy: 0.9840 - val_loss: 0.4213 - val_accuracy: 0.8889\n",
      "Epoch 3/20\n",
      "120/120 [==============================] - 504s 4s/step - loss: 0.0079 - accuracy: 0.9993 - val_loss: 0.4020 - val_accuracy: 0.8500\n",
      "Epoch 4/20\n",
      "120/120 [==============================] - 496s 4s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3772 - val_accuracy: 0.8889\n",
      "Epoch 5/20\n",
      "120/120 [==============================] - 503s 4s/step - loss: 4.5555e-04 - accuracy: 1.0000 - val_loss: 0.3881 - val_accuracy: 0.8833\n",
      "Epoch 6/20\n",
      "120/120 [==============================] - 501s 4s/step - loss: 3.1243e-04 - accuracy: 1.0000 - val_loss: 0.3939 - val_accuracy: 0.8833\n",
      "Epoch 7/20\n",
      "  2/120 [..............................] - ETA: 8:14 - loss: 1.0385e-04 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3512/1254404288.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mearly_cb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatience\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mearly_cb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Machine_learning_python\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Machine_learning_python\\venv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1179\u001b[0m                 _r=1):\n\u001b[0;32m   1180\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1181\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1182\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Machine_learning_python\\venv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(it)\u001b[0m\n\u001b[0;32m    862\u001b[0m           args=(it, self._steps_per_execution.numpy().item()))\n\u001b[0;32m    863\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 864\u001b[1;33m       self.train_function = lambda it: train_function(  # pylint: disable=g-long-lambda\n\u001b[0m\u001b[0;32m    865\u001b[0m           \u001b[0mit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m           self._steps_per_execution.numpy().item())\n",
      "\u001b[1;32m~\\Machine_learning_python\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Machine_learning_python\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Machine_learning_python\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Machine_learning_python\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3018\u001b[0m       (graph_function,\n\u001b[0;32m   3019\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3020\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3021\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Machine_learning_python\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\Machine_learning_python\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Machine_learning_python\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "early_cb = keras.callbacks.EarlyStopping(patience = 5)\n",
    "\n",
    "model.fit(train_set, epochs=20, validation_data = val_set, callbacks = [early_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6772ef71",
   "metadata": {},
   "source": [
    "### Note: the batch size (32) is probably too large for this scenario (244x244 pictures), and it makes training veeery slow... Let's go back and repeat everything with a smaller one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3b98de75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 13s 761ms/step - loss: 0.3534 - accuracy: 0.8722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3533640503883362, 0.8722222447395325]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set)  # 87% accuracy on the test set... Pretty bad. Probably because the dataset is not very good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fbe77379",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 2s 0us/step\n",
      "9420800/9406464 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.MobileNetV2(include_top = False, weights='imagenet')\n",
    "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)  # makes the final layer shorter and accessible to a dense layer\n",
    "output = keras.layers.Dense(6, activation = \"softmax\")(avg) \n",
    "\n",
    "light_model = keras.Model(inputs = base_model.input, outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c1ea7960",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, None, None,  0           []                               \n",
      "                                 3)]                                                              \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, None, None,   864         ['input_6[0][0]']                \n",
      "                                32)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, None, None,   128         ['Conv1[0][0]']                  \n",
      "                                32)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, None, None,   0           ['bn_Conv1[0][0]']               \n",
      "                                32)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depth  (None, None, None,   288         ['Conv1_relu[0][0]']             \n",
      "wiseConv2D)                     32)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Ba  (None, None, None,   128         ['expanded_conv_depthwise[0][0]']\n",
      "tchNormalization)               32)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (  (None, None, None,   0           ['expanded_conv_depthwise_BN[0][0\n",
      "ReLU)                           32)                              ]']                              \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, None, None,   512         ['expanded_conv_depthwise_relu[0]\n",
      "                                16)                              [0]']                            \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batc  (None, None, None,   64          ['expanded_conv_project[0][0]']  \n",
      "hNormalization)                 16)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, None, None,   1536        ['expanded_conv_project_BN[0][0]'\n",
      "                                96)                              ]                                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormal  (None, None, None,   384         ['block_1_expand[0][0]']         \n",
      "ization)                        96)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, None, None,   0           ['block_1_expand_BN[0][0]']      \n",
      "                                96)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, None, None,   0           ['block_1_expand_relu[0][0]']    \n",
      "                                96)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCo  (None, None, None,   864         ['block_1_pad[0][0]']            \n",
      "nv2D)                           96)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNor  (None, None, None,   384         ['block_1_depthwise[0][0]']      \n",
      "malization)                     96)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, None, None,   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                96)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, None, None,   2304        ['block_1_depthwise_relu[0][0]'] \n",
      "                                24)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNorma  (None, None, None,   96          ['block_1_project[0][0]']        \n",
      "lization)                       24)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, None, None,   3456        ['block_1_project_BN[0][0]']     \n",
      "                                144)                                                              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormal  (None, None, None,   576         ['block_2_expand[0][0]']         \n",
      "ization)                        144)                                                              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, None, None,   0           ['block_2_expand_BN[0][0]']      \n",
      "                                144)                                                              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCo  (None, None, None,   1296        ['block_2_expand_relu[0][0]']    \n",
      "nv2D)                           144)                                                              \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNor  (None, None, None,   576         ['block_2_depthwise[0][0]']      \n",
      "malization)                     144)                                                              \n",
      "__________________________________________________________________________________________________\n",

      "            ...                            ...                            ...                       "
      
      "Total params: 2,265,670\n",
      "Trainable params: 7,686\n",
      "Non-trainable params: 2,257,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False  # freezing the pretrained model for now\n",
    "    \n",
    "light_model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    optimizer = keras.optimizers.Nadam(learning_rate = 0.001), \n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "light_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "83e11ab7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "120/120 [==============================] - 35s 275ms/step - loss: 1.2635 - accuracy: 0.5250 - val_loss: 1.1749 - val_accuracy: 0.5111\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 33s 274ms/step - loss: 0.9013 - accuracy: 0.6757 - val_loss: 1.0991 - val_accuracy: 0.5944\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 33s 276ms/step - loss: 0.7659 - accuracy: 0.7319 - val_loss: 1.0620 - val_accuracy: 0.6278\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 33s 274ms/step - loss: 0.6775 - accuracy: 0.7653 - val_loss: 1.0410 - val_accuracy: 0.6222\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 33s 273ms/step - loss: 0.6122 - accuracy: 0.7951 - val_loss: 1.0286 - val_accuracy: 0.6444\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 33s 275ms/step - loss: 0.5606 - accuracy: 0.8118 - val_loss: 1.0212 - val_accuracy: 0.6611\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 33s 274ms/step - loss: 0.5181 - accuracy: 0.8306 - val_loss: 1.0169 - val_accuracy: 0.6556\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 33s 274ms/step - loss: 0.4822 - accuracy: 0.8486 - val_loss: 1.0147 - val_accuracy: 0.6611\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 33s 275ms/step - loss: 0.4510 - accuracy: 0.8625 - val_loss: 1.0139 - val_accuracy: 0.6667\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 34s 285ms/step - loss: 0.4235 - accuracy: 0.8743 - val_loss: 1.0141 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x165a1ee0610>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_cb = keras.callbacks.EarlyStopping(patience = 3)\n",
    "\n",
    "light_model.fit(train_set, epochs=10, validation_data = val_set, callbacks = [early_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a4607cb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, None, None,  0           []                               \n",
      "                                 3)]                                                              \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, None, None,   864         ['input_6[0][0]']                \n",
      "                                32)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, None, None,   128         ['Conv1[0][0]']                  \n",
      "                                32)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, None, None,   0           ['bn_Conv1[0][0]']               \n",
      "                                32)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depth  (None, None, None,   288         ['Conv1_relu[0][0]']             \n",
      "wiseConv2D)                     32)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Ba  (None, None, None,   128         ['expanded_conv_depthwise[0][0]']\n",
      "tchNormalization)               32)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (  (None, None, None,   0           ['expanded_conv_depthwise_BN[0][0\n",
      "ReLU)                           32)                              ]']                              \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, None, None,   512         ['expanded_conv_depthwise_relu[0]\n",
      "                                16)                              [0]']                            \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batc  (None, None, None,   64          ['expanded_conv_project[0][0]']  \n",
      "hNormalization)                 16)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, None, None,   1536        ['expanded_conv_project_BN[0][0]'\n",
      "                                96)                              ]                                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormal  (None, None, None,   384         ['block_1_expand[0][0]']         \n",
      "ization)                        96)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, None, None,   0           ['block_1_expand_BN[0][0]']      \n",
      "                                96)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, None, None,   0           ['block_1_expand_relu[0][0]']    \n",
      "                                96)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCo  (None, None, None,   864         ['block_1_pad[0][0]']            \n",
      "nv2D)                           96)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNor  (None, None, None,   384         ['block_1_depthwise[0][0]']      \n",
      "malization)                     96)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, None, None,   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                96)                                                               \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, None, None,   2304        ['block_1_depthwise_relu[0][0]'] \n",
      "                                24)                                                               \n",
      "__________________________________________________________________________________________________\n",

      "            ...                            ...                            ...                       "
      
      "Total params: 2,265,670\n",
      "Trainable params: 2,231,558\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = True  # UNfreezing the pretrained model for now\n",
    "    \n",
    "light_model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    optimizer = keras.optimizers.Nadam(learning_rate = 0.0001), \n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "light_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3737fac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "120/120 [==============================] - 177s 1s/step - loss: 0.9212 - accuracy: 0.6972 - val_loss: 2.2406 - val_accuracy: 0.4278\n",
      "Epoch 2/20\n",
      "120/120 [==============================] - 164s 1s/step - loss: 0.0545 - accuracy: 0.9896 - val_loss: 1.8668 - val_accuracy: 0.5056\n",
      "Epoch 3/20\n",
      "120/120 [==============================] - 166s 1s/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.3749 - val_accuracy: 0.6222\n",
      "Epoch 4/20\n",
      "120/120 [==============================] - 164s 1s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.1410 - val_accuracy: 0.6778\n",
      "Epoch 5/20\n",
      "120/120 [==============================] - 178s 1s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.9814 - val_accuracy: 0.7167\n",
      "Epoch 6/20\n",
      "120/120 [==============================] - 171s 1s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8348 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "120/120 [==============================] - 171s 1s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7465 - val_accuracy: 0.7778\n",
      "Epoch 8/20\n",
      "120/120 [==============================] - 172s 1s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6884 - val_accuracy: 0.7944\n",
      "Epoch 9/20\n",
      "120/120 [==============================] - 171s 1s/step - loss: 9.4134e-04 - accuracy: 1.0000 - val_loss: 0.6491 - val_accuracy: 0.7889\n",
      "Epoch 10/20\n",
      "120/120 [==============================] - 170s 1s/step - loss: 7.9387e-04 - accuracy: 1.0000 - val_loss: 0.6043 - val_accuracy: 0.7889\n",
      "Epoch 11/20\n",
      "120/120 [==============================] - 172s 1s/step - loss: 6.7817e-04 - accuracy: 1.0000 - val_loss: 0.5619 - val_accuracy: 0.7833\n",
      "Epoch 12/20\n",
      "120/120 [==============================] - 171s 1s/step - loss: 5.8566e-04 - accuracy: 1.0000 - val_loss: 0.5372 - val_accuracy: 0.8111\n",
      "Epoch 13/20\n",
      "120/120 [==============================] - 172s 1s/step - loss: 5.1028e-04 - accuracy: 1.0000 - val_loss: 0.5227 - val_accuracy: 0.8167\n",
      "Epoch 14/20\n",
      "120/120 [==============================] - 171s 1s/step - loss: 4.4799e-04 - accuracy: 1.0000 - val_loss: 0.5150 - val_accuracy: 0.8389\n",
      "Epoch 15/20\n",
      "120/120 [==============================] - 171s 1s/step - loss: 3.9583e-04 - accuracy: 1.0000 - val_loss: 0.5127 - val_accuracy: 0.8444\n",
      "Epoch 16/20\n",
      "120/120 [==============================] - 171s 1s/step - loss: 3.5172e-04 - accuracy: 1.0000 - val_loss: 0.5135 - val_accuracy: 0.8444\n",
      "Epoch 17/20\n",
      "120/120 [==============================] - 171s 1s/step - loss: 3.1406e-04 - accuracy: 1.0000 - val_loss: 0.5153 - val_accuracy: 0.8500\n",
      "Epoch 18/20\n",
      "120/120 [==============================] - 171s 1s/step - loss: 2.8167e-04 - accuracy: 1.0000 - val_loss: 0.5174 - val_accuracy: 0.8500\n",
      "Epoch 19/20\n",
      "120/120 [==============================] - 169s 1s/step - loss: 2.5359e-04 - accuracy: 1.0000 - val_loss: 0.5170 - val_accuracy: 0.8556\n",
      "Epoch 20/20\n",
      "120/120 [==============================] - 165s 1s/step - loss: 2.2911e-04 - accuracy: 1.0000 - val_loss: 0.5161 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16637915640>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_cb = keras.callbacks.EarlyStopping(patience = 5)\n",
    "\n",
    "light_model.fit(train_set, epochs=20, validation_data = val_set, callbacks = [early_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ebb912fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 4s 259ms/step - loss: 0.6218 - accuracy: 0.8222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6218278408050537, 0.8222222328186035]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light_model.evaluate(test_set)  # way faster, but less accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb4289e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
